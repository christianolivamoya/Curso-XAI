{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "fm4Q9T4-DAjT",
        "MDTjeOt0HK-N",
        "iVZ1z2B-KlxO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"#F48E16\">Formación en XAI de Deep Learning: Coeficiente de Explicabilidad Rendimiento</font>\n",
        "\n",
        "Material generado por <a href=\"https://www.linkedin.com/in/christian-oliva-moya-ingeniero/\">Christian Oliva</a>. Cualquier duda, sugerencia o errata, no duden en contactar.\n",
        "\n",
        "**Versión 1.0** - 29 de agosto de 2025"
      ],
      "metadata": {
        "id": "UCifH99yDFhy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyQtY74_C_Fz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import kagglehub\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#F48E16\">Datos</font>"
      ],
      "metadata": {
        "id": "fm4Q9T4-DAjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook se muestra la implementación manual de los diferentes algoritmos de explicabilidad genérica vistos durante el curso, que son los siguientes:\n",
        "\n",
        "- Importancia por permutación\n",
        "\n",
        "- Relevancia por oclusión\n",
        "\n",
        "- SHAP\n",
        "\n",
        "- LIME\n",
        "\n",
        "Para ello, se van a utilizar diferentes modelos sencillos de SKLearn sobre un dataset de riesgo financiero para la aprobación de préstamos: **Loan Approval Classification Dataset**\n",
        "\n",
        "https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data\n",
        "\n",
        "<hr>\n",
        "\n",
        "En el notebook se desarrolla el código por completo según una fase sencilla de preprocesamiento de los datos, el entrenamiento de algunos modelos y la explicabilidad utilizando los diferentes algoritmos."
      ],
      "metadata": {
        "id": "Tlc01dsEDONY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descarga de datos de Kaggle"
      ],
      "metadata": {
        "id": "YA8BtQG6EMxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"taweilo/loan-approval-classification-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "yqn5V1wNEJY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path + \"/loan_data.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "HN2v0Vcezmft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"person_age\"] = np.log(np.clip(data[\"person_age\"], 0, 70))\n",
        "data[\"person_gender\"] = data[\"person_gender\"].replace({\"female\":0, \"male\":1})\n",
        "data[\"person_education\"] = data[\"person_education\"].replace({\"High School\":0, \"Associate\":1, \"Bachelor\":2, \"Master\":3, \"Doctorate\":4})\n",
        "data[\"person_income\"] = np.log(data[\"person_income\"])\n",
        "data[\"person_emp_exp\"] = np.log(data[\"person_emp_exp\"]+1)\n",
        "data = pd.concat((data, pd.get_dummies(data[\"person_home_ownership\"], prefix=\"person_home_ownership_\")), axis=1)\n",
        "data = data.drop(columns=[\"person_home_ownership\"])\n",
        "data[\"loan_amnt\"] = np.log(data[\"loan_amnt\"])\n",
        "data = pd.concat((data, pd.get_dummies(data[\"loan_intent\"], prefix=\"loan_intent_\")), axis=1)\n",
        "data = data.drop(columns=[\"loan_intent\"])\n",
        "data[\"loan_percent_income\"] = np.log(data[\"loan_percent_income\"]+0.1)\n",
        "data[\"cb_person_cred_hist_length\"] = np.log(data[\"cb_person_cred_hist_length\"])\n",
        "data[\"previous_loan_defaults_on_file\"] = data[\"previous_loan_defaults_on_file\"].replace({\"No\": 0, \"Yes\": 1})"
      ],
      "metadata": {
        "id": "eOzrcLW6EV5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separación en TRAIN-TEST y normalización"
      ],
      "metadata": {
        "id": "nvYAA5EfGx1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=[\"loan_status\"])\n",
        "y = data[\"loan_status\"]"
      ],
      "metadata": {
        "id": "kUzbYvmIG4jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Jww8zxpaG5yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means = X_train_raw.mean()\n",
        "stds = X_train_raw.std()\n",
        "X_train = (X_train_raw-means) / stds\n",
        "X_test = (X_test_raw-means) / stds"
      ],
      "metadata": {
        "id": "pm-bo1dYG2Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.describe()"
      ],
      "metadata": {
        "id": "4rsiuyTgGuXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas = X_train_raw.columns\n",
        "columnas"
      ],
      "metadata": {
        "id": "gsF0_wMAM1mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.values\n",
        "y_train = y_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values"
      ],
      "metadata": {
        "id": "b9Xkukf1M98M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "7xZukxZ9G9jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#F48E16\">Modelos</font>"
      ],
      "metadata": {
        "id": "MDTjeOt0HK-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Logística (modelo lineal)"
      ],
      "metadata": {
        "id": "f-vE3s97Hk5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rl = LogisticRegression()\n",
        "rl.fit(X_train, y_train)\n",
        "pred = rl.predict(X_test)\n",
        "rl.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "CBBZHeGAG-2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, pred, normalize=\"true\"), annot=True)\n",
        "plt.ylabel(\"Real\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C2kY3aJMIF5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel().tolist()\n",
        "\n",
        "print(\" > ACCURACY:\", (tp+tn)/(tp+tn+fp+fn))\n",
        "print(\" > PRECISION:\", tp/(tp+fp))\n",
        "print(\" > RECALL:\", tp/(tp+fn))"
      ],
      "metadata": {
        "id": "uZ8xpXgHHxqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "THIoUYI5KKPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red = MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000)\n",
        "red.fit(X_train, y_train)\n",
        "pred = red.predict(X_test)\n",
        "red.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "mN6T3I1uJk2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, pred, normalize=\"true\"), annot=True)\n",
        "plt.ylabel(\"Real\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UkQmhHMaKW2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel().tolist()\n",
        "\n",
        "print(\" > ACCURACY:\", (tp+tn)/(tp+tn+fp+fn))\n",
        "print(\" > PRECISION:\", tp/(tp+fp))\n",
        "print(\" > RECALL:\", tp/(tp+fn))"
      ],
      "metadata": {
        "id": "MaQvMGrhKYOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#F48E16\">Explicabilidad</font>"
      ],
      "metadata": {
        "id": "iVZ1z2B-KlxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: Por simplicidad para los algoritmos más pesados, vamos a utilizar solo un trocito de X_train como si fuese nuestro dataset completo."
      ],
      "metadata": {
        "id": "-c1pD8e-ODJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_small = X_train[:100]\n",
        "y_train_small = y_train[:100]"
      ],
      "metadata": {
        "id": "qu5OAWcrVTfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importancia por permutación [Método global]"
      ],
      "metadata": {
        "id": "AYi_-s_LKsc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La importancia por permutación consiste en permutar uno a uno los atributos del dataset de entrada y evaluar el modelo M para ver cómo se modifica su rendimiento. La relevancia, por tanto, se define así:\n",
        "\n",
        "$$R_i = M(X) - \\frac{1}{N} \\sum_{j=1}^N M(X'_i)$$\n",
        "\n",
        "donde $R_i$ es la relevancia del atributo $i$-ésimo, $M(X)$ representa la métrica de rendimiento del modelo $M$ a partir del dataset original $X$, $N$ es el número de repeticiones para promediar, y $X'_i$ hace referencia al dataset original X habiendo permutado el atributo $i$-ésimo.\n",
        "\n",
        "**¿Por qué se hace esto?**\n",
        "\n",
        "Porque si se pierde rendimiento cuando se rompe el atributo $i$-ésimo, esto significa que dicho atributo es importante para el modelo.\n",
        "\n",
        "Este algoritmo de explicabilidad es un método global, ya que utiliza todo el dataset para dar un valor global de la relevancia de un atributo."
      ],
      "metadata": {
        "id": "MvbGzTKNKvVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def importancia_permutacion(X, y, model, N=10):\n",
        "    Rx = np.zeros(X.shape[1])\n",
        "    for i in tqdm(range(X.shape[1])):\n",
        "        for j in range(N):\n",
        "            X_perm = X.copy()\n",
        "            np.random.shuffle(X_perm[:, i])\n",
        "            Rx[i] += model.score(X_perm, y)\n",
        "    Rx = model.score(X, y) - Rx / N\n",
        "    return Rx"
      ],
      "metadata": {
        "id": "-peyTprCL0yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_perm_rl = importancia_permutacion(X_train, y_train, rl, N=10)\n",
        "Rx_perm_red = importancia_permutacion(X_train, y_train, red, N=10)"
      ],
      "metadata": {
        "id": "kMxMIT6oMevo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relevancia por oclusión [Método local y global]"
      ],
      "metadata": {
        "id": "JVdy5PCLV8v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La relevancia por oclusión, en general, se utiliza como técnica de explicabilidad de modelos que procesan imágenes, pero, aunque es una técnica que veremos más adelante aplicada a dicha tarea, también puede ser utilizada en problemas tabulares. La relevancia por oclusión es un método híbrido, que puede ser aplicado de forma tanto local (para una observación concreta) como global (para todo el dataset), que consiste en anular una región del espacio de atributos de entrada.\n",
        "\n",
        "El término anular consiste en reemplazar un atributo $i$-ésimo por un valor \"inteligente\", por ejemplo:\n",
        "\n",
        "- Un valor fijo 0\n",
        "\n",
        "- La media del atributo\n",
        "\n",
        "- La moda del atributo\n",
        "\n",
        "- Un valor imputado mediante un algoritmo más complejo\n",
        "\n",
        "La relevancia por oclusión global para datos tabulares se calcula, entonces, de la siguiente manera:\n",
        "\n",
        "$$R_i = M(X) - M(X'_i)$$\n",
        "\n",
        "donde $M(X)$ representa una métrica de rendimiento del modelo $M$ al procesar el dataset $X$ y $M(X'_i)$ representa la misma métrica de rendimiento al procesar el dataset con el atributo $i$-ésimo anulado.\n",
        "\n",
        "Sin embargo, si se busca la oclusión a nivel local, se calcularía de la siguiente manera:\n",
        "\n",
        "$$R_i(x) = f(x) - f(x'_i)$$\n",
        "\n",
        "donde $f(x)$ es la predicción del modelo para el dato de entrada $x$ y $f(x'_i)$ es la predicción del mismo modelo para el dato de entrada $x$ con el atributo $i$-ésimo anulado.\n",
        "\n",
        "**¿Por qué se sigue esta estrategia?**\n",
        "\n",
        "Esta estrategia se basa en una idea parecida a la importancia por permutación, donde se evalúa el modelo después de modificar un atributo de entrada del dataset.\n",
        "\n",
        "En el siguiente código se va a utilizar el valor fijo 0 porque es la media de los atributos de entrada, ya que están normalizados."
      ],
      "metadata": {
        "id": "PsX8FPznu4gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relevancia_oclusion(X, y, model, verbose=True):\n",
        "  if X.ndim == 1: # 1 solo dato, lo ponemos en formato matricial\n",
        "    X = X[None, :]\n",
        "    pred = model.predict_proba(X)\n",
        "  else:\n",
        "    score = model.score(X, y)\n",
        "\n",
        "  num_atributos = X.shape[-1]\n",
        "\n",
        "  iterador_num_atributos = tqdm(range(num_atributos)) if verbose else range(num_atributos)\n",
        "  Rx = np.zeros(num_atributos)\n",
        "  for i in iterador_num_atributos:\n",
        "    X_null = X.copy()\n",
        "    X_null[:, i] = 0\n",
        "    if X.shape[0] == 1: # solo un dato, relevancia local\n",
        "      Rx[i] = pred[0,y] - model.predict_proba(X_null)[0,y]\n",
        "    else: # más de un dato, relevancia global\n",
        "      Rx[i] = score - model.score(X_null, y)\n",
        "  return Rx"
      ],
      "metadata": {
        "id": "I_LBJlWnTseL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevancia global**"
      ],
      "metadata": {
        "id": "Z1QQrVJczn5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_oclu_rl = relevancia_oclusion(X_train, y_train, rl)\n",
        "Rx_oclu_red = relevancia_oclusion(X_train, y_train, red)"
      ],
      "metadata": {
        "id": "vcEw7jn_zkjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevancia local**"
      ],
      "metadata": {
        "id": "VUQs28is1T0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a explicar un dato particular."
      ],
      "metadata": {
        "id": "62wRe1Wa1Xl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item = 0"
      ],
      "metadata": {
        "id": "rGbth6A31aeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_oclu_local_rl = relevancia_oclusion(X_train_small[item], y_train_small[item], rl)\n",
        "Rx_oclu_local_red = relevancia_oclusion(X_train_small[item], y_train_small[item], red)"
      ],
      "metadata": {
        "id": "pYLwuBKi1MZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP (SHapley Additive exPlanations)"
      ],
      "metadata": {
        "id": "Td7RJrpU-XO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El valor de Shapley en teoría de juegos para una característica $i$-ésima es el siguiente:\n",
        "\n",
        "$$\\phi_i(x) = \\sum_{S\\subseteq F\\setminus \\{i\\}} \\frac{|S|!(|F|-|S|-1)!}{|F|!} [f_{S\\cup \\{i\\}}(x) - f_S(x)]$$\n",
        "\n",
        "donde $F$ es el conjunto de todos los atributos (features) y $f_S(x)$ es la predicción del modelo cuando sólo usamos los atributos de $S$, imputando el resto. Es decir, hay que calcular todas las permutaciones posibles de todos los atributos con todos los atributos excepto el $i$-ésimo. Como esto es exponencial y no es viable, lo que se hace en la práctica es **muestrear permutaciones aleatorias de atributos**.\n",
        "\n",
        "¿En qué consiste la idea? En ir introduciendo de forma aleatoria atributos a la instancia del dataset, imputando el resto de atributos (con la media por ejemplo) y evaluando cómo afecta incorporar ese atributo a la decisión del modelo. Podemos basarnos en esta idea:\n",
        "\n",
        "$$contribución_i = f_{S\\cup \\{i\\}}(x) - f_S(x)$$\n",
        "\n",
        "SHAP es, por tanto, un método de explicabilidad local que utiliza la imputación conforme al total de los datos para explicar una instancia particular del dataset."
      ],
      "metadata": {
        "id": "yI43indw-9l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shap(X, y, model, item, N=10, verbose=True):\n",
        "    num_atributos = X.shape[1]\n",
        "    shap_values = np.zeros(num_atributos)\n",
        "    x = X[item][None, :]\n",
        "    y = y[item]\n",
        "\n",
        "    baseline = model.predict_proba(X).mean(axis=0, keepdims=True)\n",
        "\n",
        "    iterador_N = tqdm(range(N)) if verbose else range(N)\n",
        "    for _ in iterador_N:\n",
        "      prev_pred = baseline\n",
        "      perm = np.random.permutation(num_atributos)\n",
        "      for c, i in enumerate(perm):\n",
        "        x_S = x.copy()\n",
        "        x_S[:, perm[c+1:]] = X.mean(axis=0)[perm[c+1:]] # Esta estrategia puede ser diferente\n",
        "        pred = model.predict_proba(x_S)\n",
        "        shap_values[i] += (pred - prev_pred)[0,y]\n",
        "        prev_pred = pred\n",
        "\n",
        "    return shap_values / N"
      ],
      "metadata": {
        "id": "onzd_eF8_RV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_shap_rl = shap(X_train_small, y_train_small, rl, item=0, N=50)\n",
        "Rx_shap_red = shap(X_train_small, y_train_small, red, item=0, N=50)"
      ],
      "metadata": {
        "id": "7oN1G0uGEcFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LIME (Local Interpretable Model-agnostic Explanations)"
      ],
      "metadata": {
        "id": "CAwrLg5oJXzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIME es un algoritmo de explicabilidad local basado en la idea de aproximar el comportamiento del modelo complejo con puntos cercanos a la instancia que se quiere explicar utilizando un modelo lineal.\n",
        "\n",
        "¿Cómo funciona la idea?\n",
        "\n",
        "1. Generamos un dataset sintético $X'$ alrededor de la instancia $x$.\n",
        "2. Se calculan las predicciones del modelo complejo sobre $X'$.\n",
        "3. Se asignan pesos a los puntos de $X'$ según su cercanía a la instancia $x$.\n",
        "4. Se entrena un modelo lineal con los puntos de $X'$ según la cercanía.\n",
        "\n",
        "Así, el modelo lineal aprende cómo cambian las predicciones alrededor de $x$. Además, **los pesos del modelo lineal son los valores de relevancia de cada atributo**.\n",
        "\n",
        "LIME, al contrario que SHAP, no hace combinaciones exhaustivas, sino que solo mira el vecindario cercano a la instancia $x$."
      ],
      "metadata": {
        "id": "9fNwD7o-KzLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lime(X, y, model, item, D=1000):\n",
        "  num_atributos = X.shape[1]\n",
        "  x0 = X[item][None, :]\n",
        "  y = y[item]\n",
        "\n",
        "  # 1. Generamos dataset sintetico X_perturbed alrededor de x0\n",
        "  X_perturbed = np.repeat(x0, D, axis=0)\n",
        "  noise = np.random.normal(size=X_perturbed.shape) * X.std(axis=0, keepdims=True)\n",
        "  X_perturbed += noise\n",
        "\n",
        "  # 2. Se calculan las predicciones del modelo sobre X_perturbed\n",
        "  y_perturbed = model.predict_proba(X_perturbed)[:, y]\n",
        "\n",
        "  # 3. Se asignan pesos a los puntos de X_perturbed según la distancia a x0\n",
        "  distances = np.linalg.norm(X_perturbed - x0, axis=1) + 1e-8\n",
        "  weights = 1 / distances # más distancia, menor peso. Esta estrategia puede ser diferente\n",
        "\n",
        "  # 4. Se entrena un modelo lineal con los puntos de X_perturbed\n",
        "  linear_model = LinearRegression()\n",
        "  linear_model.fit(X_perturbed, y_perturbed, sample_weight=weights) # NO OLVIDAR sample_weights\n",
        "  Rx = linear_model.coef_\n",
        "\n",
        "  return Rx"
      ],
      "metadata": {
        "id": "cdk5-lvHI4C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_lime_rl = lime(X_train_small, y_train_small, rl, 0)\n",
        "Rx_lime_red = lime(X_train_small, y_train_small, red, 0)"
      ],
      "metadata": {
        "id": "DVzhCEm5MeqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#F48E16\">Coeficiente de Explicabilidad-Rendimiento</font>"
      ],
      "metadata": {
        "id": "X-FprCN_MVOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Coeficiente de Explicabilidad-Rendimiento, propuesto en la tesis del autor, consiste en realizar dos pruebas concretas sobre las que construir una métrica:\n",
        "\n",
        "Dada la explicabilidad de un modelo *M* o, en otras palabras, la relevancia de los atributos de entrada *R* para ese modelo *M* y una métrica de evaluación *m* de *M*, como puede ser el porcentaje de acierto (*accuracy*) en un problema de clasificación, o el coeficiente de determinación R2 en un problema de regresión, si se define un umbral *U* que divide *R* en atributos relevantes (*R > U*) y no relevantes (*R < U*), se proponen dos pruebas:\n",
        "\n",
        "- **Prueba 1**: Anulando para todos los patrones de entrada los atributos que quedan por debajo del umbral según *R < U*, se puede volver a evaluar el modelo *M* y calcular la métrica $m^+$ sobre el conjunto de atributos relevantes supervivientes.\n",
        "\n",
        "- **Prueba 2**: Anulando para todos los patrones de entrada los atributos que quedan por encima del umbral según *R > U*, se puede volver a evaluar el modelo *M* y calcular la métrica $m^-$ sobre el conjunto de atributos no relevantes supervivientes.\n",
        "\n",
        "Con estas pruebas, se sigue la siguiente hipótesis:\n",
        "\n",
        "**Si se selecciona el conjunto de atributos más relevantes $ar$ del total de atributos $at$ y el resto se anulan, el rendimiento del modelo $m^+$ no debe verse afectado de manera significativa y, en el caso contrario, el rendimiento del modelo $m^-$ debe reducirse considerablemente.**\n",
        "\n",
        "Siguiendo esta hipótesis, se propone el Coeficiente de Explicabilidad Rendimiento como:\n",
        "\n",
        "$$EPC(M|R,U) = \\frac{at-ar}{at} \\times \\frac{m^+ - m^-}{m}$$\n",
        "\n",
        "El EPC mide el equilibrio entre el porcentaje de atributos considerados como relevantes frente al rendimiento del modelo. Maximizar el EPC consistirá en identificar y eliminar atributos no relevantes sin disminuir el rendimiento del modelo."
      ],
      "metadata": {
        "id": "QhQfB9NsFoZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hay que diferenciar si la explicabilidad es global o local**\n",
        "\n",
        "- Si la explicabilidad es global, hay un único valor de $R_i$ para cada atributo, por lo que se anulan todos los atributos del dataset según el único umbral $R_i$.\n",
        "\n",
        "- Si la explicabilidad es local, hay un valor de $R_{ij}$ para cada atributo e instancia del dataset, por lo que, para cada instancia del dataset, hay que definir un umbral $U_{ij}$ para cada atributo."
      ],
      "metadata": {
        "id": "4lH8ORi-KH1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epc(X, y, model, Rx, local=False):\n",
        "  at = Rx.shape[-1]\n",
        "  m = model.score(X, y)\n",
        "  epc_all = []\n",
        "  if not local:\n",
        "    ######################\n",
        "    # TO-DO Implementa EPC con un Rx global\n",
        "    ######################\n",
        "\n",
        "  else:\n",
        "    ######################\n",
        "    # TO-DO Implementa EPC con un Rx local\n",
        "    ######################\n",
        "\n",
        "  return np.array(epc_all)"
      ],
      "metadata": {
        "id": "mN1afcdqNIXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cuando la explicabilidad es global"
      ],
      "metadata": {
        "id": "gn7qaApHS-he"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos repetir el mismo Rx para todo el dataset"
      ],
      "metadata": {
        "id": "wWID1Yfr1ls8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epc_perm_rl = epc(X_train, y_train, rl, np.repeat(Rx_perm_rl[None, :], X_train.shape[0], axis=0))\n",
        "epc_oclu_rl = epc(X_train, y_train, rl, np.repeat(Rx_oclu_rl[None, :], X_train.shape[0], axis=0))\n",
        "epc_perm_red = epc(X_train, y_train, red, np.repeat(Rx_perm_red[None, :], X_train.shape[0], axis=0))\n",
        "epc_oclu_red = epc(X_train, y_train, red, np.repeat(Rx_oclu_red[None, :], X_train.shape[0], axis=0))"
      ],
      "metadata": {
        "id": "shM3-9SSNXmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epc_perm_rl, label=\"Permutación\")\n",
        "plt.plot(epc_oclu_rl, label=\"Oclusión global\")\n",
        "plt.xlabel(\"Atributos eliminados\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"EPC\")\n",
        "plt.grid(alpha=0.2)"
      ],
      "metadata": {
        "id": "KzIIZxR_OXMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epc_perm_red, label=\"Permutación\")\n",
        "plt.plot(epc_oclu_red, label=\"Oclusión global\")\n",
        "plt.xlabel(\"Atributos eliminados\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"EPC\")\n",
        "plt.grid(alpha=0.2)"
      ],
      "metadata": {
        "id": "GGTjiBEdRAR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cuando la explicabilidad es local"
      ],
      "metadata": {
        "id": "CLG_PlWUTD46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necesitamos calcular la relevancia de cada instancia del dataset. Por eso utilizamos `X_train_small` con solo 100 datos, para no tardar mucho."
      ],
      "metadata": {
        "id": "Qk-5JGPqMCdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_oclu_local_rl = np.array([relevancia_oclusion(X_train_small[item], y_train_small[item], rl, verbose=False) for item in range(len(X_train_small))])\n",
        "Rx_oclu_local_red = np.array([relevancia_oclusion(X_train_small[item], y_train_small[item], red, verbose=False) for item in range(len(X_train_small))])"
      ],
      "metadata": {
        "id": "X_odvHOvY_yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP tarda un ratito\n",
        "Rx_shap_rl = np.array([shap(X_train_small, y_train_small, rl, item, N=50, verbose=False) for item in range(len(X_train_small))])\n",
        "Rx_shap_red = np.array([shap(X_train_small, y_train_small, red, item, N=50, verbose=False) for item in range(len(X_train_small))])"
      ],
      "metadata": {
        "id": "Nf0xqqTOe7XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_lime_rl = np.array([lime(X_train_small, y_train_small, rl, item) for item in range(len(X_train_small))])\n",
        "Rx_lime_red = np.array([lime(X_train_small, y_train_small, red, item) for item in range(len(X_train_small))])"
      ],
      "metadata": {
        "id": "jpy6kElzfKcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observación**: El EPC se basa en anular atributos, por lo que tenemos que modificar LIME para que nos indique el comportamiento correcto."
      ],
      "metadata": {
        "id": "LIhIzCAmMTMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epc_oclu_local_rl = epc(X_train_small, y_train_small, rl, Rx_oclu_local_rl, local=True)\n",
        "epc_oclu_local_red = epc(X_train_small, y_train_small, red, Rx_oclu_local_red, local=True)\n",
        "epc_shap_rl = epc(X_train_small, y_train_small, rl, Rx_shap_rl, local=True)\n",
        "epc_shap_red = epc(X_train_small, y_train_small, red, Rx_shap_red, local=True)\n",
        "epc_lime_rl = epc(X_train_small, y_train_small, rl, (Rx_lime_rl*np.sign(X_train_small)), local=True) # Tenemos que multiplicar aquí por el signo de x\n",
        "epc_lime_red = epc(X_train_small, y_train_small, red, (Rx_lime_red*np.sign(X_train_small)), local=True) # Aquí igual"
      ],
      "metadata": {
        "id": "L_2Aec8yTK_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epc_perm_rl, label=\"Permutación\")\n",
        "plt.plot(epc_oclu_rl, label=\"Oclusión global\")\n",
        "plt.plot(epc_oclu_local_rl, label=\"Oclusión local\")\n",
        "plt.plot(epc_shap_rl, label=\"SHAP\")\n",
        "plt.plot(epc_lime_rl, label=\"LIME\")\n",
        "plt.xlabel(\"Atributos eliminados\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"EPC\")\n",
        "plt.grid(alpha=0.2)"
      ],
      "metadata": {
        "id": "4Dhuh_yCVGjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epc_perm_red, label=\"Permutación\")\n",
        "plt.plot(epc_oclu_red, label=\"Oclusión global\")\n",
        "plt.plot(epc_oclu_local_red, label=\"Oclusión local\")\n",
        "plt.plot(epc_shap_red, label=\"SHAP\")\n",
        "plt.plot(epc_lime_red, label=\"LIME\")\n",
        "plt.xlabel(\"Atributos eliminados\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"EPC\")\n",
        "plt.grid(alpha=0.2)"
      ],
      "metadata": {
        "id": "ELNPTIJfhlzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Conclusiones? ¿Dudas?**\n",
        "\n",
        "- El EPC nos permite evaluar cuántos atributos puedo eliminar sin perder rendimiento (o con una pérdida de rendimiento razonable).\n",
        "\n",
        "- El EPC de los algoritmos locales es mayor que el de los algoritmos globales. Tiene sentido por la especificidad al dato de entrada en lugar de al global de los datos.\n",
        "\n",
        "- Aparentemente, los tres algoritmos de explicabilidad local tienen un rendimiento similar."
      ],
      "metadata": {
        "id": "9BHSgj5-MuI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "n9-VGiu9NULg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permitidme modificar el código del EPC para devolver también el $m^+$."
      ],
      "metadata": {
        "id": "P6UWTjeANOLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta función la dará el profesor en clase\n",
        "def epc_all_data(X, y, model, Rx, local=False):\n",
        "  pass"
      ],
      "metadata": {
        "id": "KUOSVps9jnP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epc_oclu_local_rl, mmas_oclu_local_rl = epc_all_data(X_train_small, y_train_small, rl, Rx_oclu_local_rl, local=True)\n",
        "epc_oclu_local_red, mmas_oclu_local_red = epc_all_data(X_train_small, y_train_small, red, Rx_oclu_local_red, local=True)\n",
        "epc_shap_rl, mmas_shap_rl = epc_all_data(X_train_small, y_train_small, rl, Rx_shap_rl, local=True)\n",
        "epc_shap_red, mmas_shap_red = epc_all_data(X_train_small, y_train_small, red, Rx_shap_red, local=True)\n",
        "epc_lime_rl, mmas_lime_rl = epc_all_data(X_train_small, y_train_small, rl, (Rx_lime_rl*np.sign(X_train_small)), local=True) # Tenemos que multiplicar aquí por el signo de x\n",
        "epc_lime_red, mmas_lime_red = epc_all_data(X_train_small, y_train_small, red, (Rx_lime_red*np.sign(X_train_small)), local=True) # Aquí igual"
      ],
      "metadata": {
        "id": "qAAc3FBONqNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epc_oclu_local_red, label=\"Oclusión local\")\n",
        "plt.plot(epc_shap_red, label=\"SHAP\")\n",
        "plt.plot(epc_lime_red, label=\"LIME\")\n",
        "plt.xlabel(\"Atributos eliminados\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"EPC\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(mmas_oclu_local_red, '.-', label=\"Oclusión local\")\n",
        "plt.plot(mmas_shap_red, '.-', label=\"SHAP\")\n",
        "plt.plot(mmas_lime_red, '.-', label=\"LIME\")\n",
        "plt.xlabel(\"Atributos eliminados\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"Acc prueba 1: $m^+$\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sYMIfR7XN7Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Qué está sucediendo?**\n",
        "\n",
        "- El accuracy de la prueba 1 $m^+$ está subiendo al 100%. ¿Por qué? ¿Es correcto?\n",
        "\n",
        "**Decisión personal**\n",
        "\n",
        "- Visto lo visto, yo me quedaría por ahora con la oclusión local por ser más suave la curva (gusto personal). El que parece que es un poco peor es LIME según el EPC."
      ],
      "metadata": {
        "id": "XAIvH0FvOmNY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Boq6FDxFN9rS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}