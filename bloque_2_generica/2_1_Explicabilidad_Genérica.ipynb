{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "fm4Q9T4-DAjT",
        "MDTjeOt0HK-N",
        "iVZ1z2B-KlxO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"#F48E16\">Formación en XAI de Deep Learning: Explicabilidad Genérica</font>\n",
        "\n",
        "Material generado por <a href=\"https://www.linkedin.com/in/christian-oliva-moya-ingeniero/\">Christian Oliva</a>. Cualquier duda, sugerencia o errata, no duden en contactar.\n",
        "\n",
        "**Versión 1.0** - 29 de agosto de 2025"
      ],
      "metadata": {
        "id": "UCifH99yDFhy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyQtY74_C_Fz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import kagglehub\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#F48E16\">Datos</font>"
      ],
      "metadata": {
        "id": "fm4Q9T4-DAjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook se muestra la implementación manual de los diferentes algoritmos de explicabilidad genérica vistos durante el curso, que son los siguientes:\n",
        "\n",
        "- Importancia por permutación\n",
        "\n",
        "- Relevancia por oclusión\n",
        "\n",
        "- SHAP\n",
        "\n",
        "- LIME\n",
        "\n",
        "Para ello, se van a utilizar diferentes modelos sencillos de SKLearn sobre un dataset de riesgo financiero para la aprobación de préstamos: **Loan Approval Classification Dataset**\n",
        "\n",
        "https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data\n",
        "\n",
        "<hr>\n",
        "\n",
        "En el notebook se desarrolla el código por completo según una fase sencilla de preprocesamiento de los datos, el entrenamiento de algunos modelos y la explicabilidad utilizando los diferentes algoritmos."
      ],
      "metadata": {
        "id": "Tlc01dsEDONY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descarga de datos de Kaggle"
      ],
      "metadata": {
        "id": "YA8BtQG6EMxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"taweilo/loan-approval-classification-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "yqn5V1wNEJY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Primer vistazo de los datos"
      ],
      "metadata": {
        "id": "ITU0ivqtEPtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path + \"/loan_data.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "LbBFQfmXEKe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "a19jel-GESH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "DfAV6jKhEUDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocesamiento"
      ],
      "metadata": {
        "id": "BoUZxJ1vEX_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Person Age"
      ],
      "metadata": {
        "id": "7NSGjIcREl_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"person_age\"]\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "sT71rfX_EsOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable = np.clip(variable, 0, 70)\n",
        "variable = np.log(variable)\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "snLJ8wBHEzL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Person Income"
      ],
      "metadata": {
        "id": "WDou84QxE4pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"person_income\"]\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "pk041TTZE7BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(variable).hist(bins=31)"
      ],
      "metadata": {
        "id": "K0k74MoLE8mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Person Emp Exp (años de experiencia)"
      ],
      "metadata": {
        "id": "qVIKItRiE_IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"person_emp_exp\"]\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "K3NH10cGFCfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable = np.log(variable+1) # Sumo 1 para evitar -inf\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "qcWXokTlFDtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Person Home Ownership (situación de propiedad de la vivienda)"
      ],
      "metadata": {
        "id": "0vYzU0u4FIyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los únicos valores posibles son RENT (alquiler), OWN (propiedad), MORTGAGE (hipoteca) y OTHER (otro)."
      ],
      "metadata": {
        "id": "NvbkFo2yFNac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"person_home_ownership\"]\n",
        "variable.unique()"
      ],
      "metadata": {
        "id": "Yx9_uVWlFH4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(variable, prefix=\"person_home_ownership_\")"
      ],
      "metadata": {
        "id": "sMp_GU78FVUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loan Amnt (valor del préstamo)"
      ],
      "metadata": {
        "id": "lcAGVrlHFzxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"loan_amnt\"]\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "nNg_1V1eF4IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable = np.log(variable)\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "prfkrOKKF5o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loan Intent (finalidad del préstamo)"
      ],
      "metadata": {
        "id": "r24P00iPF68U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiene un conjunto finito de valores: PERSONAL (personal), EDUCATION (educación), VENTURE (médico), HOMEIMPROVEMENT (mejora del hogar) y DEBTCONSOLIDATION (consolidación de deudas)."
      ],
      "metadata": {
        "id": "l_F7JaoBGArA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"loan_intent\"]\n",
        "variable.unique()"
      ],
      "metadata": {
        "id": "HI3vjex3F-ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(variable, prefix=\"loan_intent_\")"
      ],
      "metadata": {
        "id": "XZB-LVRVGGX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loan Int Rate (tipo de interés)"
      ],
      "metadata": {
        "id": "SKN72G7TGDpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"loan_int_rate\"]\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "Xw9YxNbwGITM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loan Percent Income (pct del préstamo respecto a los ingresos anuales)"
      ],
      "metadata": {
        "id": "21ghvgUKGJ3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"loan_percent_income\"]\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "96f5TInGGRUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable = np.log(variable+1e-1)\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "HA15XkyxGVL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cb Person Cred Hist Length (duración del crédito)"
      ],
      "metadata": {
        "id": "FQQef7chGWjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"cb_person_cred_hist_length\"]\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "ch6GMoOdGZ9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable = np.log(variable)\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "4EO8tIafGcOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Credit Score"
      ],
      "metadata": {
        "id": "EIo4pqsmGdZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"credit_score\"]\n",
        "variable.hist(bins=31)"
      ],
      "metadata": {
        "id": "_KQa4iLdGhcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Previous Loan Defaults on File (impagos anteriores)"
      ],
      "metadata": {
        "id": "DXs6Z-GvGkkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable = data[\"previous_loan_defaults_on_file\"]\n",
        "variable.unique()"
      ],
      "metadata": {
        "id": "fX6gOtQiGn13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable.replace({\"No\": 0, \"Yes\": 1})"
      ],
      "metadata": {
        "id": "gmcajAy7GosN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO JUNTO"
      ],
      "metadata": {
        "id": "Ch-z4teaEqIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"person_age\"] = np.log(np.clip(data[\"person_age\"], 0, 70))\n",
        "data[\"person_gender\"] = data[\"person_gender\"].replace({\"female\":0, \"male\":1})\n",
        "data[\"person_education\"] = data[\"person_education\"].replace({\"High School\":0, \"Associate\":1, \"Bachelor\":2, \"Master\":3, \"Doctorate\":4})\n",
        "data[\"person_income\"] = np.log(data[\"person_income\"])\n",
        "data[\"person_emp_exp\"] = np.log(data[\"person_emp_exp\"]+1)\n",
        "data = pd.concat((data, pd.get_dummies(data[\"person_home_ownership\"], prefix=\"person_home_ownership_\")), axis=1)\n",
        "data = data.drop(columns=[\"person_home_ownership\"])\n",
        "data[\"loan_amnt\"] = np.log(data[\"loan_amnt\"])\n",
        "data = pd.concat((data, pd.get_dummies(data[\"loan_intent\"], prefix=\"loan_intent_\")), axis=1)\n",
        "data = data.drop(columns=[\"loan_intent\"])\n",
        "data[\"loan_percent_income\"] = np.log(data[\"loan_percent_income\"]+0.1)\n",
        "data[\"cb_person_cred_hist_length\"] = np.log(data[\"cb_person_cred_hist_length\"])\n",
        "data[\"previous_loan_defaults_on_file\"] = data[\"previous_loan_defaults_on_file\"].replace({\"No\": 0, \"Yes\": 1})"
      ],
      "metadata": {
        "id": "eOzrcLW6EV5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "S_lXFmneGtj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separación en TRAIN-TEST y normalización"
      ],
      "metadata": {
        "id": "nvYAA5EfGx1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=[\"loan_status\"])\n",
        "y = data[\"loan_status\"]"
      ],
      "metadata": {
        "id": "kUzbYvmIG4jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Jww8zxpaG5yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means = X_train_raw.mean()\n",
        "stds = X_train_raw.std()\n",
        "X_train = (X_train_raw-means) / stds\n",
        "X_test = (X_test_raw-means) / stds"
      ],
      "metadata": {
        "id": "pm-bo1dYG2Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.describe()"
      ],
      "metadata": {
        "id": "4rsiuyTgGuXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas = X_train_raw.columns\n",
        "columnas"
      ],
      "metadata": {
        "id": "gsF0_wMAM1mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.values\n",
        "y_train = y_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values"
      ],
      "metadata": {
        "id": "b9Xkukf1M98M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "7xZukxZ9G9jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#F48E16\">Modelos</font>"
      ],
      "metadata": {
        "id": "MDTjeOt0HK-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Logística (modelo lineal)"
      ],
      "metadata": {
        "id": "f-vE3s97Hk5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rl = LogisticRegression()\n",
        "rl.fit(X_train, y_train)\n",
        "pred = rl.predict(X_test)\n",
        "rl.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "CBBZHeGAG-2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, pred, normalize=\"true\"), annot=True)\n",
        "plt.ylabel(\"Real\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C2kY3aJMIF5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel().tolist()\n",
        "\n",
        "print(\" > ACCURACY:\", (tp+tn)/(tp+tn+fp+fn))\n",
        "print(\" > PRECISION:\", tp/(tp+fp))\n",
        "print(\" > RECALL:\", tp/(tp+fn))"
      ],
      "metadata": {
        "id": "uZ8xpXgHHxqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "fugV5ru6I5L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", max_iter=2000, probability=True)\n",
        "svc.fit(X_train, y_train)\n",
        "pred = svc.predict(X_test)\n",
        "svc.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "AI8xhR_SIpbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, pred, normalize=\"true\"), annot=True)\n",
        "plt.ylabel(\"Real\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sPW3eagbJRG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel().tolist()\n",
        "\n",
        "print(\" > ACCURACY:\", (tp+tn)/(tp+tn+fp+fn))\n",
        "print(\" > PRECISION:\", tp/(tp+fp))\n",
        "print(\" > RECALL:\", tp/(tp+fn))"
      ],
      "metadata": {
        "id": "KcWXSKzcJj9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "THIoUYI5KKPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red = MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000)\n",
        "red.fit(X_train, y_train)\n",
        "pred = red.predict(X_test)\n",
        "red.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "mN6T3I1uJk2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, pred, normalize=\"true\"), annot=True)\n",
        "plt.ylabel(\"Real\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UkQmhHMaKW2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel().tolist()\n",
        "\n",
        "print(\" > ACCURACY:\", (tp+tn)/(tp+tn+fp+fn))\n",
        "print(\" > PRECISION:\", tp/(tp+fp))\n",
        "print(\" > RECALL:\", tp/(tp+fn))"
      ],
      "metadata": {
        "id": "MaQvMGrhKYOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#F48E16\">Explicabilidad</font>"
      ],
      "metadata": {
        "id": "iVZ1z2B-KlxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: Por simplicidad para los algoritmos más pesados, vamos a utilizar solo un trocito de X_train como si fuese nuestro dataset completo."
      ],
      "metadata": {
        "id": "-c1pD8e-ODJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_small = X_train[:100]\n",
        "y_train_small = y_train[:100]"
      ],
      "metadata": {
        "id": "qu5OAWcrVTfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importancia por permutación [Método global]"
      ],
      "metadata": {
        "id": "AYi_-s_LKsc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La importancia por permutación consiste en permutar uno a uno los atributos del dataset de entrada y evaluar el modelo M para ver cómo se modifica su rendimiento. La relevancia, por tanto, se define así:\n",
        "\n",
        "$$R_i = M(X) - \\frac{1}{N} \\sum_{j=1}^N M(X'_i)$$\n",
        "\n",
        "donde $R_i$ es la relevancia del atributo $i$-ésimo, $M(X)$ representa la métrica de rendimiento del modelo $M$ a partir del dataset original $X$, $N$ es el número de repeticiones para promediar, y $X'_i$ hace referencia al dataset original X habiendo permutado el atributo $i$-ésimo.\n",
        "\n",
        "**¿Por qué se hace esto?**\n",
        "\n",
        "Porque si se pierde rendimiento cuando se rompe el atributo $i$-ésimo, esto significa que dicho atributo es importante para el modelo.\n",
        "\n",
        "Este algoritmo de explicabilidad es un método global, ya que utiliza todo el dataset para dar un valor global de la relevancia de un atributo."
      ],
      "metadata": {
        "id": "MvbGzTKNKvVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def importancia_permutacion(X, y, model, N=10):\n",
        "    Rx = np.zeros(X.shape[1])\n",
        "\n",
        "    ##################################\n",
        "    # TO-DO Implementa el algoritmo de importancia por permutación\n",
        "    ##################################\n",
        "\n",
        "    return Rx"
      ],
      "metadata": {
        "id": "-peyTprCL0yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_perm_rl = importancia_permutacion(X_train_small, y_train_small, rl, N=10)\n",
        "Rx_perm_svc = importancia_permutacion(X_train_small, y_train_small, svc, N=10)\n",
        "Rx_perm_red = importancia_permutacion(X_train_small, y_train_small, red, N=10)"
      ],
      "metadata": {
        "id": "kMxMIT6oMevo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(columnas, Rx_perm_rl)\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZXpsE24RMnhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(columnas, Rx_perm_svc)\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aD5IIJb3RGKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(columnas, Rx_perm_red)\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n4tLMR4KRV4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(columnas))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(x - width, Rx_perm_rl, width, label=\"Regresión Logística\")\n",
        "plt.bar(x, Rx_perm_svc, width, label=\"SVC\")\n",
        "plt.bar(x + width, Rx_perm_red, width, label=\"Red Neuronal\")\n",
        "plt.xticks(x, columnas, rotation=90)\n",
        "plt.ylabel(\"Importancia por Permutación\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qhST7RiQSoXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Conclusiones?**\n",
        "\n",
        "Yo diría que...\n",
        "\n",
        "- Si para 3 modelos distintos hay atributos que tienen siempre relevancia con magnitud bajita, es que esos atributos sobran en el dataset.\n",
        "\n",
        "- Si hay algunos atributos que siempre tienen relevancia alta, ya sea por arriba o por abajo, es que son relevantes en el dataset.\n",
        "\n",
        "- La clave está en que algunos atributos son útiles para algún modelo pero inútiles para otro. Eso significa que estás explicando el modelo en particular y no seleccionando atributos en general."
      ],
      "metadata": {
        "id": "LmVqvRxBVAHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relevancia por oclusión [Método local y global]"
      ],
      "metadata": {
        "id": "JVdy5PCLV8v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La relevancia por oclusión, en general, se utiliza como técnica de explicabilidad de modelos que procesan imágenes, pero, aunque es una técnica que veremos más adelante aplicada a dicha tarea, también puede ser utilizada en problemas tabulares. La relevancia por oclusión es un método híbrido, que puede ser aplicado de forma tanto local (para una observación concreta) como global (para todo el dataset), que consiste en anular una región del espacio de atributos de entrada.\n",
        "\n",
        "El término anular consiste en reemplazar un atributo $i$-ésimo por un valor \"inteligente\", por ejemplo:\n",
        "\n",
        "- Un valor fijo 0\n",
        "\n",
        "- La media del atributo\n",
        "\n",
        "- La moda del atributo\n",
        "\n",
        "- Un valor imputado mediante un algoritmo más complejo\n",
        "\n",
        "La relevancia por oclusión global para datos tabulares se calcula, entonces, de la siguiente manera:\n",
        "\n",
        "$$R_i = M(X) - M(X'_i)$$\n",
        "\n",
        "donde $M(X)$ representa una métrica de rendimiento del modelo $M$ al procesar el dataset $X$ y $M(X'_i)$ representa la misma métrica de rendimiento al procesar el dataset con el atributo $i$-ésimo anulado.\n",
        "\n",
        "Sin embargo, si se busca la oclusión a nivel local, se calcularía de la siguiente manera:\n",
        "\n",
        "$$R_i(x) = f(x) - f(x'_i)$$\n",
        "\n",
        "donde $f(x)$ es la predicción del modelo para el dato de entrada $x$ y $f(x'_i)$ es la predicción del mismo modelo para el dato de entrada $x$ con el atributo $i$-ésimo anulado.\n",
        "\n",
        "**¿Por qué se sigue esta estrategia?**\n",
        "\n",
        "Esta estrategia se basa en una idea parecida a la importancia por permutación, donde se evalúa el modelo después de modificar un atributo de entrada del dataset.\n",
        "\n",
        "En el siguiente código se va a utilizar el valor fijo 0 porque es la media de los atributos de entrada, ya que están normalizados."
      ],
      "metadata": {
        "id": "PsX8FPznu4gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relevancia_oclusion(X, y, model, verbose=True):\n",
        "  if X.ndim == 1: # 1 solo dato, lo ponemos en formato matricial\n",
        "    X = X[None, :]\n",
        "    pred = model.predict_proba(X)\n",
        "  else:\n",
        "    score = model.score(X, y)\n",
        "\n",
        "  num_atributos = X.shape[-1]\n",
        "\n",
        "  Rx = np.zeros(num_atributos)\n",
        "  ##################################\n",
        "  # TO-DO Implementa la relevancia por oclusión tanto global como local\n",
        "  ##################################\n",
        "\n",
        "  return Rx"
      ],
      "metadata": {
        "id": "I_LBJlWnTseL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevancia global**"
      ],
      "metadata": {
        "id": "Z1QQrVJczn5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_oclu_rl = relevancia_oclusion(X_train_small, y_train_small, rl)\n",
        "Rx_oclu_svc = relevancia_oclusion(X_train_small, y_train_small, svc)\n",
        "Rx_oclu_red = relevancia_oclusion(X_train_small, y_train_small, red)"
      ],
      "metadata": {
        "id": "vcEw7jn_zkjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(columnas))\n",
        "width = 0.3\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(x - width/2, Rx_perm_rl, width, label=\"Importancia por permutación\")\n",
        "plt.bar(x + width/2, Rx_oclu_rl, width, label=\"Relevancia por oclusión\")\n",
        "plt.xticks(x, columnas, rotation=90)\n",
        "plt.title(\"Regresión Logística\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rr-MQWKKzuzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(columnas))\n",
        "width = 0.3\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(x - width/2, Rx_perm_svc, width, label=\"Importancia por permutación\")\n",
        "plt.bar(x + width/2, Rx_oclu_svc, width, label=\"Relevancia por oclusión\")\n",
        "plt.xticks(x, columnas, rotation=90)\n",
        "plt.title(\"SVC\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5N1YsB1W07lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(columnas))\n",
        "width = 0.3\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(x - width/2, Rx_perm_red, width, label=\"Importancia por permutación\")\n",
        "plt.bar(x + width/2, Rx_oclu_red, width, label=\"Relevancia por oclusión\")\n",
        "plt.xticks(x, columnas, rotation=90)\n",
        "plt.title(\"Red Neuronal\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ZBwPyfZzz49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como hemos podido ver, **dos métodos diferentes de explicabilidad dan dos resultados también diferentes**."
      ],
      "metadata": {
        "id": "pXHAUqBU-aGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevancia local**"
      ],
      "metadata": {
        "id": "VUQs28is1T0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a explicar un dato particular."
      ],
      "metadata": {
        "id": "62wRe1Wa1Xl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item = 0"
      ],
      "metadata": {
        "id": "rGbth6A31aeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_oclu_local_rl = relevancia_oclusion(X_train_small[item], y_train_small[item], rl)\n",
        "Rx_oclu_local_svc = relevancia_oclusion(X_train_small[item], y_train_small[item], svc)\n",
        "Rx_oclu_local_red = relevancia_oclusion(X_train_small[item], y_train_small[item], red)"
      ],
      "metadata": {
        "id": "pYLwuBKi1MZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(columnas))\n",
        "width = 0.3\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(x - width/2, Rx_oclu_rl, width, label=\"Global\")\n",
        "plt.bar(x + width/2, Rx_oclu_local_rl, width, label=\"Local item=\"+str(item))\n",
        "plt.xticks(x, columnas, rotation=90)\n",
        "plt.title(\"Relevancia por oclusión con Regresión Logística\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sbncs9Ja1fQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Por qué con el item=0 pasa que loan_percent_income, por ejemplo, es negativo?"
      ],
      "metadata": {
        "id": "oAgJMUPf4fOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero vemos el dato original y su predicción:"
      ],
      "metadata": {
        "id": "v9VrwvfW_aem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(columnas, X_train_small[item])\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(alpha=0.2)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([0, 1], rl.predict_proba(X_train_small[item][None, :])[0], \"o\")\n",
        "plt.xticks([0, 1], [\"Clase 0\", \"Clase 1\"])\n",
        "plt.title(\"Clase real: \" + str(y_train_small[item]))\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PQP-nbRy2fXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a anular **loan_percent_income**, es decir, hacerlo más pequeño."
      ],
      "metadata": {
        "id": "CZrZjWnA_d5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_null = X_train_small[item].copy()\n",
        "X_null = X_null[None, :]\n",
        "X_null[:, 7] = 0\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(columnas, X_null[0])\n",
        "plt.bar(columnas, X_train_small[item], alpha=0.2)\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(alpha=0.2)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([0, 1], rl.predict_proba(X_train_small[item][None, :])[0], \"o\", label=\"Original\")\n",
        "plt.plot([0, 1], rl.predict_proba(X_null)[0], 'o', label=\"Anulado\")\n",
        "plt.xticks([0, 1], [\"Clase 0\", \"Clase 1\"])\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ¿Tiene sentido?\n",
        "# Si anulas un atributo cuya explicabilidad con oclusión es negativa,\n",
        "# la predicción de la clase real AUMENTA"
      ],
      "metadata": {
        "id": "7ijCUFzM5UGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a anular ahora **loan_amnt**, es decir, bajarlo."
      ],
      "metadata": {
        "id": "iWi5lT2fFLiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_null = X_train_small[item].copy()\n",
        "X_null = X_null[None, :]\n",
        "X_null[:, 5] = 0\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(columnas, X_null[0])\n",
        "plt.bar(columnas, X_train_small[item], alpha=0.2)\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(alpha=0.2)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([0, 1], rl.predict_proba(X_train_small[item][None, :])[0], \"o\", label=\"Original\")\n",
        "plt.plot([0, 1], rl.predict_proba(X_null)[0], 'o', label=\"Anulado\")\n",
        "plt.xticks([0, 1], [\"Clase 0\", \"Clase 1\"])\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ¿Tiene sentido?\n",
        "# Si anulas un atributo cuya explicabilidad con oclusión es positiva,\n",
        "# la predicción de la clase real DISMINUYE"
      ],
      "metadata": {
        "id": "YZP6xcoa4nRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP (SHapley Additive exPlanations)"
      ],
      "metadata": {
        "id": "Td7RJrpU-XO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El valor de Shapley en teoría de juegos para una característica $i$-ésima es el siguiente:\n",
        "\n",
        "$$\\phi_i(x) = \\sum_{S\\subseteq F\\setminus \\{i\\}} \\frac{|S|!(|F|-|S|-1)!}{|F|!} [f_{S\\cup \\{i\\}}(x) - f_S(x)]$$\n",
        "\n",
        "donde $F$ es el conjunto de todos los atributos (features) y $f_S(x)$ es la predicción del modelo cuando sólo usamos los atributos de $S$, imputando el resto. Es decir, hay que calcular todas las permutaciones posibles de todos los atributos con todos los atributos excepto el $i$-ésimo. Como esto es exponencial y no es viable, lo que se hace en la práctica es **muestrear permutaciones aleatorias de atributos**.\n",
        "\n",
        "¿En qué consiste la idea? En ir introduciendo de forma aleatoria atributos a la instancia del dataset, imputando el resto de atributos (con la media por ejemplo) y evaluando cómo afecta incorporar ese atributo a la decisión del modelo. Podemos basarnos en esta idea:\n",
        "\n",
        "$$contribución_i = f_{S\\cup \\{i\\}}(x) - f_S(x)$$\n",
        "\n",
        "SHAP es, por tanto, un método de explicabilidad local que utiliza la imputación conforme al total de los datos para explicar una instancia particular del dataset."
      ],
      "metadata": {
        "id": "yI43indw-9l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shap(X, y, model, item, N=10, verbose=True):\n",
        "    num_atributos = X.shape[1]\n",
        "    shap_values = np.zeros(num_atributos)\n",
        "    x = X[item][None, :]\n",
        "    y = y[item]\n",
        "\n",
        "    ##################################\n",
        "    # TO-DO Implementa SHAP\n",
        "    ##################################\n",
        "\n",
        "    return shap_values / N"
      ],
      "metadata": {
        "id": "onzd_eF8_RV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_shap_rl = shap(X_train_small, y_train_small, rl, item=0, N=50)"
      ],
      "metadata": {
        "id": "7oN1G0uGEcFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(columnas))\n",
        "width = 0.3\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(x - width/2, Rx_shap_rl, width, label=\"SHAP\")\n",
        "plt.bar(x + width/2, Rx_oclu_local_rl, width, label=\"Oclusión local\")\n",
        "plt.xticks(x, columnas, rotation=90)\n",
        "plt.title(\"Relevancia por oclusión con Regresión Logística\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gx69qV5VFdV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observación**: Relevancia por oclusión y SHAP dan una relevancia que se basa en la misma idea. Añadir o quitar atributos y ver la variación en la respuesta del modelo. Tiene sentido que sean resultados parecidos."
      ],
      "metadata": {
        "id": "IrH4joz7A9UY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LIME (Local Interpretable Model-agnostic Explanations)"
      ],
      "metadata": {
        "id": "CAwrLg5oJXzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIME es un algoritmo de explicabilidad local basado en la idea de aproximar el comportamiento del modelo complejo con puntos cercanos a la instancia que se quiere explicar utilizando un modelo lineal.\n",
        "\n",
        "¿Cómo funciona la idea?\n",
        "\n",
        "1. Generamos un dataset sintético $X'$ alrededor de la instancia $x$.\n",
        "2. Se calculan las predicciones del modelo complejo sobre $X'$.\n",
        "3. Se asignan pesos a los puntos de $X'$ según su cercanía a la instancia $x$.\n",
        "4. Se entrena un modelo lineal con los puntos de $X'$ según la cercanía.\n",
        "\n",
        "Así, el modelo lineal aprende cómo cambian las predicciones alrededor de $x$. Además, **los pesos del modelo lineal son los valores de relevancia de cada atributo**.\n",
        "\n",
        "LIME, al contrario que SHAP, no hace combinaciones exhaustivas, sino que solo mira el vecindario cercano a la instancia $x$."
      ],
      "metadata": {
        "id": "9fNwD7o-KzLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lime(X, y, model, item, D=1000):\n",
        "  num_atributos = X.shape[1]\n",
        "  x0 = X[item][None, :]\n",
        "  y = y[item]\n",
        "\n",
        "  Rx = None\n",
        "\n",
        "  ##################################\n",
        "  # TO-DO Implementa LIME\n",
        "  ##################################\n",
        "\n",
        "  return Rx"
      ],
      "metadata": {
        "id": "cdk5-lvHI4C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rx_lime_rl = lime(X_train_small, y_train_small, rl, 0)"
      ],
      "metadata": {
        "id": "DVzhCEm5MeqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(columnas))\n",
        "width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.bar(x - width, Rx_shap_rl, width, label=\"SHAP\")\n",
        "plt.bar(x, Rx_oclu_local_rl, width, label=\"Oclusión local\")\n",
        "plt.bar(x + width, Rx_lime_rl, width, label=\"LIME\")\n",
        "plt.xticks(x, columnas, rotation=90)\n",
        "plt.title(\"Relevancia con Regresión Logística\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()\n",
        "\n",
        "# WOW ¿Qué está pasando en LIME? previous_loan_defaults_on_file tiene el signo cambiado?"
      ],
      "metadata": {
        "id": "WMMGishQMxsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a volver a ver el dato original"
      ],
      "metadata": {
        "id": "yWhS_NoaB125"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(columnas, X_train_small[item])\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(alpha=0.2)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([0, 1], rl.predict_proba(X_train_small[item][None, :])[0], \"o\")\n",
        "plt.xticks([0, 1], [\"Clase 0\", \"Clase 1\"])\n",
        "plt.title(\"Clase real: \" + str(y_train_small[item]))\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FVmVW5XnBzRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fijaos la diferencia entre SHAP y Oclusión frente a LIME. ¿Cómo interpretamos las cosas? Os dejo por aquí una tabla resumen teniendo en cuenta que:\n",
        "\n",
        "- SHAP y Oclusión **anulan atributos para definir la relevancia**\n",
        "- LIME **analiza la dirección del cambio**\n",
        "\n",
        "Por tanto:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td><b>Método</b></td>\n",
        "    <td><b>Interpretación</b></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><b>SHAP y Oclusión</b></td>\n",
        "    <td>Ri > 0 --> el atributo aumenta la predicción respecto al baseline, por lo que <b>anular el atributo disminuye la predicción</b>.<br>\n",
        "    Ri < 0 --> el atributo disminuye la predicción respecto al baseline, por lo que <b>anular el atributo aumenta la predicción</b>.</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>LIME</td>\n",
        "    <td>Ri > 0 --> <b>aumentar el atributo aumenta la predicción</b><br>\n",
        "    Ri < 0 --> <b>aumentar el atributo disminuye la predicción</b></td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "**Observación IMPORTANTE**: Como los datos están normalizados, anular **no siempre significa hacer más pequeño**, sino hacerlo 0. Si yo tengo $x_i = -2$, anular es hacer $x_i = 0$ (estoy aumentando el valor del atributo)."
      ],
      "metadata": {
        "id": "SFMu_2E_TBOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observación**: ¿Puedo saber la dirección de cambio con SHAP o Oclusión? Sí, simplemente multiplicando por el signo del atributo que estás evaluando: $R_i = R_i \\times sign(x_i)$. Hagámoslo con los atributos **loan_amnt** y **previous_loan_defaults_on_file**:"
      ],
      "metadata": {
        "id": "dqsSAhrnV3rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loan ammount\n",
        "print(\" > LOAN_AMNT\")\n",
        "print(\"   valor real:\", X_train_small[item][5])\n",
        "print(\"   SHAP:\", Rx_shap_rl[5])\n",
        "print(\"     que significa que si voy hacia baseline (0.0), la predicción de la clase real baja porque estoy bajando\")\n",
        "print(\"   SHAP x sign(input):\", Rx_shap_rl[5] * np.sign(X_train_small[item][5]))\n",
        "print(\"     que significa que si voy en sentido positivo, la predicción de la clase real sube\")\n",
        "print(\"   LIME:\", Rx_lime_rl[5])\n",
        "print(\"     que significa que si voy en sentido positivo, la predicción de la clase real sube\")\n",
        "print()\n",
        "\n",
        "# previous_loan_defaults_on_file\n",
        "print(\" > previous_loan_defaults_on_file\")\n",
        "print(\"   valor real:\", X_train_small[item][10])\n",
        "print(\"   SHAP:\", Rx_shap_rl[10])\n",
        "print(\"     que significa que si voy hacia baseline (0.0), la predicción de la clase real sube porque estoy subiendo\")\n",
        "print(\"   SHAP x sign(input):\", Rx_shap_rl[10] * np.sign(X_train_small[item][10]))\n",
        "print(\"     que significa que si voy en sentido positivo, la predicción de la clase real sube\")\n",
        "print(\"   LIME:\", Rx_lime_rl[10])\n",
        "print(\"     que significa que si voy en sentido positivo, la predicción de la clase real sube\")"
      ],
      "metadata": {
        "id": "zB5ApMwpOmad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Conclusiones? ¿Dudas?**\n",
        "\n",
        "- El signo de **SHAP te indica lo contrario de lo que va a pasar si anulas el atributo**. Si SHAP es negativo y anulas, la predicción sube. Si SHAP es positivo y anulas, la predicción baja.\n",
        "\n",
        "- **LIME te indica la dirección para aumentar la clase real**. Si LIME es positivo, si aumentas el atributo, la predicción sube. Si LIME es negativo, si aumentas el atributo, la predicción baja.\n",
        "\n",
        "- Multiplicar por el signo de la instancia (`np.sign(x)`) alterna entre las dos opciones, es decir, **SHAP·signo indica la dirección para aumentar la clase real**, igual que LIME; y **LIME·signo indica lo contrario de lo que va a pasar si anulas el atributo**, igual que SHAP."
      ],
      "metadata": {
        "id": "58DLrupQXyXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ¿Qué método es mejor?"
      ],
      "metadata": {
        "id": "ue76aVWDX0-H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZ1Q6E4eWU0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}